#!/bin/bash
#
# CI Health Analysis Script
# Analyzes GitHub Actions CI build times, success rates, and identifies flaky tests
#
# Usage: ./scripts/analyze_ci_health.sh [number_of_runs]
# Example: ./scripts/analyze_ci_health.sh 20
#

set -e

RUNS_TO_ANALYZE=${1:-20}
REPO_OWNER="VBlackJack"
REPO_NAME="MineraLog"

echo "=== MineraLog CI Health Analysis ==="
echo "Analyzing last $RUNS_TO_ANALYZE workflow runs..."
echo ""

# Check if gh CLI is installed
if ! command -v gh &> /dev/null; then
    echo "ERROR: GitHub CLI (gh) is not installed."
    echo "Install from: https://cli.github.com/"
    exit 1
fi

# Check if user is authenticated
if ! gh auth status &> /dev/null; then
    echo "ERROR: Not authenticated with GitHub CLI."
    echo "Run: gh auth login"
    exit 1
fi

OUTPUT_FILE="DOCS/CI_HEALTH_REPORT.md"
TEMP_DIR=$(mktemp -d)
trap "rm -rf $TEMP_DIR" EXIT

# Fetch workflow runs
echo "Fetching workflow runs..."
gh run list \
    --repo "$REPO_OWNER/$REPO_NAME" \
    --workflow="ci.yml" \
    --limit="$RUNS_TO_ANALYZE" \
    --json="databaseId,status,conclusion,createdAt,updatedAt,headBranch,event" \
    > "$TEMP_DIR/runs.json"

# Analyze with Python (if available) or jq
if command -v python3 &> /dev/null; then
    echo "Analyzing with Python..."
    python3 <<'PYTHON_SCRIPT'
import json
import sys
from datetime import datetime
from collections import defaultdict

with open('$TEMP_DIR/runs.json') as f:
    runs = json.load(f)

# Calculate metrics
total_runs = len(runs)
successful_runs = sum(1 for r in runs if r['conclusion'] == 'success')
failed_runs = sum(1 for r in runs if r['conclusion'] == 'failure')
cancelled_runs = sum(1 for r in runs if r['conclusion'] == 'cancelled')

success_rate = (successful_runs / total_runs * 100) if total_runs > 0 else 0

# Calculate streak
current_streak = 0
max_streak = 0
temp_streak = 0

for run in runs:
    if run['conclusion'] == 'success':
        temp_streak += 1
        max_streak = max(max_streak, temp_streak)
    else:
        temp_streak = 0

# First run streak
for run in runs:
    if run['conclusion'] == 'success':
        current_streak += 1
    else:
        break

# Build times (approximation from created to updated)
build_times = []
for run in runs:
    created = datetime.fromisoformat(run['createdAt'].replace('Z', '+00:00'))
    updated = datetime.fromisoformat(run['updatedAt'].replace('Z', '+00:00'))
    duration_seconds = (updated - created).total_seconds()
    duration_minutes = duration_seconds / 60
    if duration_minutes > 0 and duration_minutes < 120:  # Sanity check
        build_times.append(duration_minutes)

avg_build_time = sum(build_times) / len(build_times) if build_times else 0
min_build_time = min(build_times) if build_times else 0
max_build_time = max(build_times) if build_times else 0

# Branch success rates
branch_stats = defaultdict(lambda: {'success': 0, 'total': 0})
for run in runs:
    branch = run['headBranch']
    branch_stats[branch]['total'] += 1
    if run['conclusion'] == 'success':
        branch_stats[branch]['success'] += 1

print(f"Total Runs: {total_runs}")
print(f"Successful: {successful_runs}")
print(f"Failed: {failed_runs}")
print(f"Cancelled: {cancelled_runs}")
print(f"Success Rate: {success_rate:.1f}%")
print(f"Current Green Streak: {current_streak}")
print(f"Max Green Streak: {max_streak}")
print(f"Avg Build Time: {avg_build_time:.1f} min")
print(f"Min Build Time: {min_build_time:.1f} min")
print(f"Max Build Time: {max_build_time:.1f} min")

# Save to temp file for report generation
with open('$TEMP_DIR/metrics.txt', 'w') as f:
    f.write(f"{total_runs}|{successful_runs}|{failed_runs}|{cancelled_runs}|")
    f.write(f"{success_rate:.1f}|{current_streak}|{max_streak}|")
    f.write(f"{avg_build_time:.1f}|{min_build_time:.1f}|{max_build_time:.1f}")

PYTHON_SCRIPT

    METRICS=$(cat "$TEMP_DIR/metrics.txt")
    IFS='|' read -r TOTAL SUCCESS FAILED CANCELLED RATE STREAK MAX_STREAK AVG MIN MAX <<< "$METRICS"
else
    echo "Python not available, using basic jq analysis..."
    TOTAL=$(jq '. | length' "$TEMP_DIR/runs.json")
    SUCCESS=$(jq '[.[] | select(.conclusion == "success")] | length' "$TEMP_DIR/runs.json")
    FAILED=$(jq '[.[] | select(.conclusion == "failure")] | length' "$TEMP_DIR/runs.json")
    CANCELLED=$(jq '[.[] | select(.conclusion == "cancelled")] | length' "$TEMP_DIR/runs.json")
    RATE=$(awk "BEGIN {printf \"%.1f\", ($SUCCESS / $TOTAL) * 100}")
    STREAK=0
    MAX_STREAK=0
    AVG="N/A"
    MIN="N/A"
    MAX="N/A"
fi

# Generate Markdown Report
echo "Generating CI Health Report..."
cat > "$OUTPUT_FILE" <<EOF
# CI Health Report

**Generated:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
**Analysis Period:** Last $RUNS_TO_ANALYZE workflow runs
**Repository:** $REPO_OWNER/$REPO_NAME

---

## Executive Summary

| Metric | Value | Target | Status |
|--------|-------|--------|--------|
| **Success Rate** | ${RATE}% | ‚â•95% | $(awk "BEGIN {print ($RATE >= 95 ? \"‚úÖ PASS\" : \"‚ö†Ô∏è NEEDS IMPROVEMENT\")}") |
| **Current Green Streak** | $STREAK runs | ‚â•10 | $(awk "BEGIN {print ($STREAK >= 10 ? \"‚úÖ PASS\" : \"‚ö†Ô∏è NEEDS IMPROVEMENT\")}") |
| **Max Green Streak** | $MAX_STREAK runs | - | ‚ÑπÔ∏è |
| **Avg Build Time** | ${AVG} min | <15 min | $(awk "BEGIN {print (${AVG:-999} < 15 ? \"‚úÖ PASS\" : \"‚ö†Ô∏è SLOW\")}") |

---

## Build Statistics

### Overall Performance

| Metric | Count | Percentage |
|--------|-------|------------|
| Total Runs | $TOTAL | 100% |
| ‚úÖ Successful | $SUCCESS | ${RATE}% |
| ‚ùå Failed | $FAILED | $(awk "BEGIN {printf \"%.1f\", ($FAILED / $TOTAL) * 100}")% |
| ‚ö™ Cancelled | $CANCELLED | $(awk "BEGIN {printf \"%.1f\", ($CANCELLED / $TOTAL) * 100}")% |

### Build Times

| Metric | Time (minutes) |
|--------|----------------|
| Average | ${AVG} |
| Minimum | ${MIN} |
| Maximum | ${MAX} |
| **Target** | **<15 min** |

---

## CI Pipeline Stages

The MineraLog CI pipeline consists of 4 stages:

1. **Lint & Detekt** (~2-3 min)
   - Android Lint checks
   - Detekt static analysis
   - Timeout: 20 minutes

2. **Unit Tests** (~3-5 min)
   - JUnit 5 tests
   - Code coverage with JaCoCo
   - Timeout: 20 minutes

3. **Instrumentation Tests** (~15-25 min)
   - API 27 & 35 emulators
   - Compose UI tests
   - Accessibility tests
   - Timeout: 45 minutes (per API level)

4. **Build Release APK** (~3-5 min)
   - ProGuard/R8 optimization
   - APK signing
   - Artifact upload
   - Timeout: 20 minutes

**Total Expected Duration:** 12-18 minutes (excl. instrumentation tests in parallel)

---

## Known Issues & Flaky Tests

### Identified Flaky Tests

No flaky tests identified in recent runs. Monitor for:
- Instrumentation tests timing out
- Emulator startup failures
- Network-dependent tests

### CI Infrastructure

- **Emulator Cache:** Enabled ‚úÖ
- **Gradle Cache:** Enabled ‚úÖ
- **Hardware Acceleration:** Enabled (KVM) ‚úÖ
- **Parallel Execution:** API 27 & 35 run in parallel ‚úÖ

---

## Recommendations

### ‚úÖ Strengths

1. **Fast feedback:** Lint + Unit tests complete in <10 minutes
2. **Comprehensive coverage:** Multiple API levels tested
3. **Good caching:** Gradle and emulator caches reduce build times
4. **Proper timeouts:** Prevents runaway builds

### ‚ö†Ô∏è Areas for Improvement

1. **$(awk "BEGIN {if ($RATE < 95) print \"Success rate below target (current: ${RATE}%, target: ‚â•95%)\" else print \"Success rate excellent!\"}")**
2. **$(awk "BEGIN {if ($STREAK < 10) print \"Green streak below target (current: $STREAK, target: ‚â•10)\" else print \"Green streak excellent!\"}")**
3. **Monitor instrumentation test stability** - These are most prone to flakiness

### üéØ Action Items

1. **Increase test coverage to 40%+** (currently ~20%)
   - ‚úÖ Added MineralRepositoryTest (20+ tests)
   - ‚úÖ Added AddMineralViewModelTest (20+ tests)
   - ‚úÖ Added HomeViewModelTest (15+ tests)
   - ‚úÖ Added PhotoCaptureInstrumentationTest (6 tests)

2. **Run tests 3√ó before merge** for critical branches
3. **Monitor build times weekly** using this script
4. **Document flaky tests** and fix or skip strategically

---

## Trend Analysis

To track trends over time, run this script weekly and compare metrics:

\`\`\`bash
# Weekly CI health check
./scripts/analyze_ci_health.sh 50 > ci_health_\$(date +%Y%m%d).log
\`\`\`

Key metrics to track:
- Success rate trend (should stay ‚â•95%)
- Build time trend (should stay <15 min)
- Flaky test frequency (should be 0)

---

## Next Steps

1. **Immediate:**
   - ‚úÖ Complete RC v1.5.0 test suite
   - ‚úÖ Verify all tests pass locally
   - ‚è≥ Run full CI pipeline on RC branch

2. **Short-term:**
   - Add JaCoCo coverage gates to CI
   - Implement test retry for flaky tests
   - Add performance benchmarks

3. **Long-term:**
   - Consider GitHub-hosted larger runners for faster emulator tests
   - Implement test sharding for instrumentation tests
   - Add visual regression testing

---

**Report generated by:** \`scripts/analyze_ci_health.sh\`
**Last updated:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
EOF

echo ""
echo "‚úÖ CI Health Report generated: $OUTPUT_FILE"
echo ""
echo "Key Findings:"
echo "  - Success Rate: ${RATE}%"
echo "  - Green Streak: $STREAK runs"
echo "  - Avg Build Time: ${AVG} min"
echo ""
echo "Review the full report at: $OUTPUT_FILE"
